{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import random\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridWorldEnvironment import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating gridworld environment\n",
    "gw = GridWorld(gamma = .9, theta = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_action_value(env):\n",
    "    q = dict()\n",
    "    for state, action, next_state, reward in env.transitions:\n",
    "        q[(state, action)] = np.random.normal()\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_greedy_policy(env, Q):\n",
    "    pi = dict()\n",
    "    for state in env.states:\n",
    "        actions = []\n",
    "        q_values = []\n",
    "        prob = []\n",
    "        \n",
    "        for a in env.actions:\n",
    "            actions.append(a)\n",
    "            q_values.append(Q[state,a])   \n",
    "        for i in range(len(q_values)):\n",
    "            if i == np.argmax(q_values):\n",
    "                prob.append(1)\n",
    "            else:\n",
    "                prob.append(0)       \n",
    "                \n",
    "        pi[state] = (actions, prob)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(env, q, state):\n",
    "    actions = env.actions\n",
    "    action_values = []\n",
    "    for action in actions:\n",
    "        action_values.append(q[state, action])\n",
    "    return actions[np.argmax(action_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(env, e, q, state):\n",
    "    actions = env.actions\n",
    "    action_values = []\n",
    "    prob = []\n",
    "    for action in actions:\n",
    "        action_values.append(q[(state, action)])\n",
    "    for i in range(len(action_values)):\n",
    "        if i == np.argmax(action_values):\n",
    "            prob.append(1 - e + e/len(action_values))\n",
    "        else:\n",
    "            prob.append(e/len(action_values))\n",
    "    return actions, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-greedy policy is an extension of e_greedy()\n",
    "def generate_e_greedy_policy(env, e, Q):\n",
    "    pi = dict()\n",
    "    for state in env.states:\n",
    "        pi[state] = e_greedy(env, e, Q, state)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritized_sweeping(env, epsilon, alpha, theta, num_iter, planning_steps):\n",
    "    Q = state_action_value(env)\n",
    "    pi = generate_e_greedy_policy(env, epsilon, Q)\n",
    "    for _ in range(num_iter):\n",
    "        current_state = np.random.choice(env.states)\n",
    "        model={}\n",
    "        pqueue = []\n",
    "        while current_state != 0:\n",
    "            current_state = np.random.choice(env.states)\n",
    "            current_action = np.random.choice(pi[current_state][0], p = pi[current_state][1])\n",
    "            next_state, reward = env.state_transition(current_state, current_action)\n",
    "            if next_state==0:\n",
    "                break            \n",
    "            model[current_state, current_action] = (next_state, reward)           \n",
    "            best_action = greedy(env, Q, next_state)    \n",
    "            P=abs(reward + env.gamma * Q[next_state, best_action] - Q[current_state, current_action])          \n",
    "            if P > theta:\n",
    "                heappush(pqueue, (current_state, current_action))\n",
    "                          \n",
    "            for n in range(planning_steps):\n",
    "                if not pqueue:\n",
    "                    break\n",
    "                state, action = heappop(pqueue)\n",
    "                new_state, new_reward = model[state, action]\n",
    "                \n",
    "                new_best_action = greedy(env, Q, new_state) \n",
    "                Q[state, action] += alpha*(new_reward + env.gamma * Q[new_state, new_best_action] - Q[state, action])\n",
    "                \n",
    "                hat=[]\n",
    "                for s_a, ns_r in model.items():\n",
    "                    if ns_r[0]==state:\n",
    "                        hat.append([s_a[0], s_a[1], ns_r[1]])\n",
    "                        \n",
    "                for item in hat:\n",
    "                    reward_hat=item[2]\n",
    "                    best_act= greedy(env, Q, state)\n",
    "                    P=abs(reward_hat + env.gamma * Q[state, best_act] - Q[item[0], item[1]])\n",
    "                    if P > theta:\n",
    "                        heappush(pqueue, (item[0], item[1]))\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = prioritized_sweeping(gw, 0.2 ,0.1, 1e-03, 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_hat = generate_greedy_policy(gw, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_policy(pi, env):\n",
    "    temp = np.zeros(len(env.states) + 2)\n",
    "    for s in env.states:\n",
    "        a = pi_hat[s][0][np.argmax(pi_hat[s][1])]\n",
    "        if a == \"U\":\n",
    "            temp[s] = 0.25\n",
    "        elif a == \"D\":\n",
    "            temp[s] = 0.5\n",
    "        elif a == \"R\":\n",
    "            temp[s] = 0.75\n",
    "        else:\n",
    "            temp[s] = 1.0\n",
    "            \n",
    "    temp = temp.reshape(4,4)\n",
    "    ax = seaborn.heatmap(temp, cmap = \"prism\", linecolor=\"#282828\", cbar = False, linewidths = 0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### RED = TERMINAL (0)\n",
    "### GREEN = LEFT\n",
    "### BLUE = UP\n",
    "### PURPLE = RIGHT\n",
    "### ORANGE = DOWN\n",
    "\n",
    "show_policy(pi_hat, gw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
